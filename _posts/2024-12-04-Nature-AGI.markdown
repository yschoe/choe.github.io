---
layout: post
title:  "[LLM][Hinton] Will digital intelligence replace biological intelligence : Geoff Hinton"
date:   October 30, 2024
categ:  none
---

Here's an interesting essay (Nature magazine): How close is AI to human-level intelligence?

The article mentions these as limitations/needs/observations:
<ul>
<li>
LLMs can't do long multi-step planning that require abstract reasoning and generalization
</li><li>
LLMs can come up with embedding with low Kolmogorov complexity (algorithmic complexity), but it cannot get better than now due to lack of more data.
</li><li>
Predicting the next token is good but not good enough to reach AGI.  It needs to generate large chunks all at once.
</li><li>
LLMs need to build good world models. Analysis of LLM's internal representations show a hint of this, but it's a mess.
</li><li>
LLMs lack internal feedback that requires recurrent connections. All connections are feedforward, and feedback only through error back propagation.
</li><li>
Need too much data (unlike humans?)
</li>
</ul>

<a href="https://www.nature.com/articles/d41586-024-03905-1">https://www.nature.com/articles/d41586-024-03905-1</a>
